<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[一道多线程练习题]]></title>
    <url>%2F2019%2F05%2F17%2F%E4%B8%80%E9%81%93%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BB%83%E4%B9%A0%E9%A2%98%2F</url>
    <content type="text"><![CDATA[有一个超长的数组，现要对数组中数字进行求和，若使用多线程~ 单元测试123456789//初始化一个超长的数组20亿（长度2的32次方最大了），随机插入数字@Beforepublic void beforeTest()&#123; arr = new ArrayList(200000000); Random random = new Random(10); for (long i=0; i &lt; 200000000; i++)&#123; arr.add(random.nextInt(10)); &#125;&#125; 一般解法 主线程里面直接累加 12345678910@Testpublic void mainTest()&#123; long startTime = System.currentTimeMillis(); long result = 0; for (int i=0; i &lt; 200000000; i++)&#123; result += arr.get(i); &#125; System.out.println("result == " + result); System.out.println("consume time : " + (System.currentTimeMillis()-startTime));&#125; 结果 result == 899943289 consume time : 187 ms 使用多线程 思路：定义一个当前数组的下标，每有一个线程获取到数组的一个当前下标的值，下标就+1；多个线程，循环同步访问数组的值，在线程内部做累加；利用CountDownLatch，使得所有线程执行完后，在对各个线程的算出的值做累加。 12345678910111213141516171819@Testpublic void mutilThreadTest()&#123; CountDownLatch countDownLatch = new CountDownLatch(10); long startTime = System.currentTimeMillis(); long result = 0; for (int j=0; j&lt;indexs.length;j++)&#123; new TestThread(countDownLatch,j).start(); &#125; try &#123; countDownLatch.await(); &#125;catch (Exception e)&#123; System.out.println("error == " + e.getMessage()); &#125; for (int i=0; i &lt; indexs.length; i++)&#123; result += indexs[i]; &#125; System.out.println("result == " + result); System.out.println("consume time : " + (System.currentTimeMillis()-startTime));&#125; 结果 result == 899943289 consume time : 10852 ms 从执行结果看出，没用多线程执行的代码，消耗时间更短； 多线程的使用为的是提高程序的执行效率，但是针对此题这样的多线程操作思路却并没有带来更高的效率，反而更慢了。多线程竞争数组、线程的同步等待，都使得性能更低了；换个思路，若将长数组进行预先分段，每个线程执行一个分段的累加，线程不在竞争而是直接执行，效率会更好（这部分思路的代码暂时不写咯~） 好好学习天天向上~分享、交流、共同进步~]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次内存泄漏问题]]></title>
    <url>%2F2019%2F04%2F17%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Esl 一个FreeSwitch外呼系统连接的客户端，由于没有人维护更新而导致的血案。 最近新接手了一个老系统——智能外呼系统，分了两个应用，一个对接的是老的外呼系统IVR（华为的一套），一个则是通过freeswitch外呼；由于IVR老的一套所用语言较老，部门内没有人懂，所以想往FS迁移；之前的同事通过ESL客户端，对接FS服务器，然后通过相关指令作外呼管理，实现了大概功能，然而存在问题，曾在生产上跑着跑着内存泄漏了😓，没解决。。。接手过来，也就轮到我们来解决问题了。。 问题重现调低JVM相关参数配置：堆内存大小和直接内存大小；手动添加外呼任务执行。等待一段时间后，failed to allocate 64(bytes) of direct memory和 OutOfDirectMemoryError问题便出现了。 问题寻找定位问题排查参考：https://www.jianshu.com/p/4e96beb37935 netty内部有对堆外内存进行计数的一个参数：计数器为 DIRECT_MEMORY_COUNTER，单位B;在 netty每次分配堆外内存之前，都会计数. 跟踪esl代码，观察计数器变化；在esl中有123456789101112/** * Specialised &#123;@link SimpleChannelInboundHandler&#125; that implements the logic of an ESL connection that * is common to both inbound and outbound clients. This * handler expects to receive decoded &#123;@link EslMessage&#125; or &#123;@link EslEvent&#125; objects. ... **/public abstract class AbstractEslClientHandler extends SimpleChannelInboundHandler&lt;EslMessage&gt;&#123; ...&#125; EslMessage为esl中对传输信息的一个封装，但它并没有实现继承ReferenceCounted，netty 4 之后，对象的生命周期由它们的引用计数（reference counts）管理，而不是由垃圾收集器（garbage collector）管理；所以导致最后分配的内存，对象引用是EslMessage，但是因为没有实现ReferenceCounted，所以最后没有通过netty释放出内存。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271public class EslFrameDecoder extends ReplayingDecoder&lt;EslFrameDecoder.State&gt; &#123; /** * Line feed character */ static final byte LF = 10; protected enum State &#123; READ_HEADER, READ_BODY, &#125; private final Logger log = LoggerFactory.getLogger(this.getClass()); private final int maxHeaderSize; private EslMessage currentMessage; private boolean treatUnknownHeadersAsBody = false; public EslFrameDecoder(int maxHeaderSize) &#123; super(State.READ_HEADER); if (maxHeaderSize &lt;= 0) &#123; throw new IllegalArgumentException( "maxHeaderSize must be a positive integer: " + maxHeaderSize); &#125; this.maxHeaderSize = maxHeaderSize; &#125; public EslFrameDecoder(int maxHeaderSize, boolean treatUnknownHeadersAsBody) &#123; this(maxHeaderSize); this.treatUnknownHeadersAsBody = treatUnknownHeadersAsBody; &#125; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf buffer, List&lt;Object&gt; out) throws Exception &#123; State state = state(); log.trace("decode() : state [&#123;&#125;]", state); switch (state) &#123; case READ_HEADER: if (currentMessage == null) &#123; currentMessage = new EslMessage(); &#125; /* * read '\n' terminated lines until reach a single '\n' */ boolean reachedDoubleLF = false; while (!reachedDoubleLF) &#123; // this will read or fail String headerLine = readToLineFeedOrFail(buffer, maxHeaderSize); log.debug("read header line [&#123;&#125;]", headerLine); if (!headerLine.isEmpty()) &#123; // split the header line String[] headerParts = HeaderParser.splitHeader(headerLine); Name headerName = Name.fromLiteral(headerParts[0]); if (headerName == null) &#123; if (treatUnknownHeadersAsBody) &#123; // cache this 'header' as a body line &lt;-- useful for Outbound client mode currentMessage.addBodyLine(headerLine); &#125; else &#123; throw new IllegalStateException("Unhandled ESL header [" + headerParts[0] + ']'); &#125; &#125; currentMessage.addHeader(headerName, headerParts[1]); &#125; else &#123; reachedDoubleLF = true; &#125; // do not read in this line again checkpoint(); &#125; // have read all headers - check for content-length if (currentMessage.hasContentLength()) &#123; checkpoint(State.READ_BODY); log.debug("have content-length, decoding body .."); // force the next section break; &#125; else &#123; // end of message checkpoint(State.READ_HEADER); // send message upstream EslMessage decodedMessage = currentMessage; currentMessage = null; out.add(decodedMessage); break; &#125; case READ_BODY: /* * read the content-length specified */ int contentLength = currentMessage.getContentLength(); ByteBuf bodyBytes = buffer.readBytes(contentLength); log.debug("read [&#123;&#125;] body bytes", bodyBytes.writerIndex()); // most bodies are line based, so split on LF while (bodyBytes.isReadable()) &#123; String bodyLine = readLine(bodyBytes, contentLength); log.debug("read body line [&#123;&#125;]", bodyLine); currentMessage.addBodyLine(bodyLine); &#125; // end of message checkpoint(State.READ_HEADER); // send message upstream EslMessage decodedMessage = currentMessage; currentMessage = null; out.add(decodedMessage); break; default: throw new Error("Illegal state: [" + state + ']'); &#125; &#125; private String readToLineFeedOrFail(ByteBuf buffer, int maxLineLegth) throws TooLongFrameException &#123; StringBuilder sb = new StringBuilder(64); while (true) &#123; // this read might fail byte nextByte = buffer.readByte(); if (nextByte == LF) &#123; return sb.toString(); &#125; else &#123; // Abort decoding if the decoded line is too large. if (sb.length() &gt;= maxLineLegth) &#123; throw new TooLongFrameException( "ESL header line is longer than " + maxLineLegth + " bytes."); &#125; sb.append((char) nextByte); &#125; &#125; &#125; private String readLine(ByteBuf buffer, int maxLineLength) throws TooLongFrameException &#123; StringBuilder sb = new StringBuilder(64); while (buffer.isReadable()) &#123; // this read should always succeed byte nextByte = buffer.readByte(); if (nextByte == LF) &#123; return sb.toString(); &#125; else &#123; // Abort decoding if the decoded line is too large. if (sb.length() &gt;= maxLineLength) &#123; throw new TooLongFrameException( "ESL message line is longer than " + maxLineLength + " bytes."); &#125; sb.append((char) nextByte); &#125; &#125; return sb.toString(); &#125;&#125; 好好学习天天向上~分享、交流、共同进步~]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>内存泄漏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试总结一]]></title>
    <url>%2F2019%2F04%2F02%2F%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%E4%B8%80%2F</url>
    <content type="text"><![CDATA[好好学习天天向上~分享、交流、共同进步~]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux常用命令]]></title>
    <url>%2F2019%2F02%2F28%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[工作中常用命令汇总 基本命令 ls list 列举 -a 列出目录所有文件，包含隐藏文件 -l 列出文件并包含文件的权限、所有者、文件大小等详细信息 ll 等价于 ls -l cd change Directory切换目录 cd / root目录 cd ~ home目录 cd .. 返回上一层 cd - 进入上一次工作路径 pwd 查看当前工作目录路径 mkdir 创建文件夹 mkdir -p 路径名 此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不在的目录,即一次可以建立多个目录; rm [选项] 文件 删除一个目录中的一个或多个文件或目录，如果没有使用 -r 选项，则rm不会删除目录。如果使用rm来删除文件，通常仍可以将该文件恢复原状 rm -i *.log 删除任何.log文件；删除前逐一询问确认； rm -rf test 删除test子目录及其目录中所有文件,并且不用一一确认； rmdir 删除目录 mv 移动文件或修改文件名，根据第二参数类型决定 mv test.log test1.txt 重命名为test1.txt mv test1.log test2.log /dir 移动两个文件到dir目录 cp 复制 -i 提示，提示是否覆盖 -r 复制目录及目录内所有项目 cp -ai test.txt /test/dist 复制test.txt到/test/dist目录下,保持源文件时间 cat ：一次显示整个文件；从键盘创建一个文件 cat &gt; filename； 将几个文件合并成一个文件。 cat -n a.log b.log 把a.log的文件内容加上行号后输入b.log这个文件里 more and less 显示内容 more +3 text.txt 显示文件中从第3行起的内容 ls -l | more -5 所列出文件目录详细信息，借助管道使每次显示5行,按空格键显示下5行 ps -aux | less -N ps查看进程信息并通过less分页显示,显示行数 tail 显示指定文件末尾内容，常用查看日志 tail -100 -f -n test.log 从后到前读取100行，且循环读取，显示行数 whereis 查看文件位置，用于程序名的搜索 locate 通过搜寻系统内建文档数据库达到快速找到档案 -r 使用正则运算式做为寻找条件 locate /etc/sh 搜索etc目录下所有以sh开头的文件 find 用于在文件树中查找文件 chmod 修改权限1234567891011权限代号： r ：读权限，用数字4表示 w ：写权限，用数字2表示 x ：执行权限，用数字1表示 - ：删除权限，用数字0表示 s ：特殊权限权限范围： u ：目录或者文件的当前的用户 g ：目录或者文件的当前的群组 o ：除了目录或者文件的当前用户或群组之外的用户或者群组 a ：所有的用户及群组 -rw-r–r– 10个位置，第一个字符表示文件类型，-表示非目录，d表示目录；从第二个字符开始到第十个共9个字符，3个字符一组，分别表示了3组用户对文件或者目录的权限。权限字符用横线代表空许可，r代表只读，w代表写，x代表可执行。 -c 当发生改变时，报告处理信息 -R 处理指定目录以及其子目录下所有文件 chmod a+x t.log 增加文件t.log所有用户可执行权限 chmod 751 t.log -c 给file的属主分配读、写、执行(7)的权限，给file的所在组分配读、执行(5)的权限，给其他用户分配执行(1)的权限 chown 将指定文件的拥有者改为指定的用户或组 chown -c mail:mail test.log 改变拥有者和群组,并显示改变信息 grep 文本搜索命令 grep -aR -100 “abc” test.log 递归循环查找文件中包含关键字的内容，显示匹配字符后的100行 ps 查看当前运行的进程状态 ps -ef 显示当前所有进程环境变量及进程间关系 kill 杀死进程 free 显示系统内存使用情况 curl 链接调用，http命令行工具 curl -o linux.html http://www.linux.com 保存网页 curl -O http://www.baidu.com/page/2/ -O http://www.baidu.com/page/3/ 保存链接网页的文件 curl -H 自定义 header -A 自定义User-Agent用户代理 使用 -d 发送 POST 请求。 好好学习天天向上~分享、交流、共同进步~]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新年2019篇]]></title>
    <url>%2F2019%2F02%2F05%2F%E6%96%B0%E5%B9%B42019%E7%AF%87%2F</url>
    <content type="text"><![CDATA[年味似乎越来越淡，但时间的路上却越来越多滋味。 2019 新的一年，老了一岁； 石座前，门栏外，柴火潇潇崔汗； 屋檐后，窗帘内，茶水噜噜解醉。 好好学习天天向上~分享、交流、共同进步~]]></content>
      <categories>
        <category>散谈</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Git 常用命令]]></title>
    <url>%2F2019%2F01%2F20%2FGit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Git分布式版本控制系统其版本管理的思想，类比树枝，有树干，树干可以衍生出多个枝干，每个枝干可以是不同的版本主题，而枝干内容也可以汇流到主树干中。 常用命令项目工作中常用命令 git init 初始化一个项目为git项目，在执行命令的目录下会生成.git隐藏的配置管理文件夹 git config –global user.name “username” 设置用户名 git config –global user.email “useremail” 设置邮箱地址(建议用注册giuhub的邮箱) git clone url 将已知项目仓库克隆到本地 git status 查看当前项目分支的状态（有没有修改新增的文件内容） git branch 显示分支列表，同时确认当前所在的分支 git check 后面跟分支名，则是切换到指定分支 后面跟 -b 分支名xxx ，创建名为xxx的分支，并且切换到xxx分支 后面跟 – [file] 还原对filename的文件的修改 git add [filename] 添加修改或新增的文件到暂存区，为提交做准备 后面跟 . 表示添加全部文件 git commit -m “备注” 提交暂存区的内容到当前分支 git log 查看提交日志 git reflog 查看仓库的操作日志 git reset –hrad commitId 回溯到指定版本状态，每次commit之后都会生成一个对应的提交ID作为一个记号，制定某个记号，即可回滚到那个记号对应的状态。 git fetch 抓取同步远程分支的分支信息 git pull origin xxx 拉去远程分支xxx的内容到当前分支 git push origin 分支名xxx 推送当前分支内容状态到远程分支xxx git stash 保存当前分支的修改内容到工作区,一个栈内 后面跟 pop ，将工作区最上层的保存的状态（修改内容）同步到当前分支 后面跟 list ，将保存的栈内容罗列出来 后面跟 apply [commitId] 恢复指定id记录的状态 后面跟 drop [commitId] 删除指定id的状态记录 git cherry-pick [options] [commitId] git cherry-pick commitid 把a分支提交的一个commitId内容，提交到b分支； 常用options: –quit 退出当前的chery-pick序列; –continue 继续当前的chery-pick序列; –abort 取消当前的chery-pick序列，恢复当前分支; -n, –no-commit 不自动提交; -e, –edit 编辑提交信息; 好好学习天天向上-分享、交流、共同进步~]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关键对话]]></title>
    <url>%2F2019%2F01%2F20%2F%E5%85%B3%E9%94%AE%E5%AF%B9%E8%AF%9D%2F</url>
    <content type="text"><![CDATA[关键对话生活工作，人与人的关系就建立在一次次的沟通对话中。当对话的你们双方观点存在很大的差距；当对话存在很大的风险，对你可能产生莫大影响；当对话的双方情绪激烈；这都是关键的对话。 面对关键对话的态度 常见的关键对话：结束一段感情；和总是冒犯你的同事交谈；让朋友还钱；指出老板一些不对的地方；向言行不一的老板提建议；批评同事的工作表现；应对处于青春期的叛逆儿女；探讨关于出轨的问题；应对配偶严重的家庭暴力问题；和喜欢打听小道消息的同事交谈；要求升职加薪… 叁無两时，我们就面对着关键的对话，逃避or情绪化的应对，都不符合我们最初的设想，那就坦诚的面对吧。 100%的坦诚，同时100%的尊重对方 从自己做起。忧虑与苦恼，往往无助于事情发展，保持自己心情的积极，更能让自己充沛精力去解决问题。情绪是控制在自己手里的，没有人能够伤害你，除非你自己允许，解决问题的方法从不是伤害或者被伤害。 战胜对方、惩罚对方、保持一团和气，这三种想法都是阻止你达成双赢沟通的障碍。 关注你的真实目的 1.学会在对话前和对话中问自己问题 我希望为自己实现什么目标;我希望为对方实现什么目标;我希望为我们之间的关系实现什么目标;要实现这些目标我该怎么做; 2.为什么要问自己问题 ①为对话寻找意义。在谈话中失控的人，都是因为已经忘记了谈话的初衷。想想看，一个为了挽救孩子的父亲，突然发飙，说随你的便吧！这时候他已经忘记了谈话的目标，成为了自己情绪的奴隶。只要记得谈话的目标，你的情绪就不容易失控。 ②控制好自己的身体。做自己的观察者，你的身体和思想才会受控。在紧张的时候，观察自己，和自己对话，能够让自己很快放松下来。 关键对话思维技巧 学会对比说明： -阐明自己的目的 -不想看到的结果 -有没有两全其美的方法 学会注意观察对话氛围 学会双核观察（注意对话内容，同时注意对话氛围）。很多对话的失败，就是因为没有关注氛围。当你发现对方情绪不对或者气氛出现不利于对话的变化时，要停止内容方面的沟通，转而修复氛围。可以用我们前面讲到的对比说明的方法。也可以直接表示你理解对方的情绪。甚至要求把对话停一停，双方冷静一点再继续谈。 尊重，保持对话安全 强调共同目的，保持尊重。尊重就像空气。它存在的时候，你感觉不到它；但一旦它不存在了，你就立刻会感受到窒息。尊重有时不是语言的问题。你的心里不尊重一个人，你会通过你的肢体语言和眼神表达出来。甚至你下意识的动作都会被对方感觉。当氛围不对时，懂得道歉，对比说明修复主题。 控制好自己的情绪 留意三种常见的小聪明:受害者想法：这可不是我的错;大反派想法：这都是你造成的;无助者想法：这事我也没办法。 关键对话步骤 分享事实经过 事实是最不会引起争议，最具说服力，最不会令人反感的内容，我们要学会从事实出发。 说出你的想法 a.不要堆积问题，自信地说出你的想法b.注意气氛安全 征询对方观点，注意倾听，为彼此寻找共同点 比如：我想听听您的想法；我想知道您对我的看法；我希望听您坦诚地讲讲对我的意见和建议 做出试探表述 鼓励做出尝试 为下一次关键对话做准备 从心开始（调整心态，自己首先摆脱暴力或沉默的状态，寻找双赢的可能） 注意观察（除了内容，还要关注谈话的氛围） 保证安全（如果对方情绪出现问题，想办法让对方觉得安全） 控制想法（不要轻易地觉得受到冒犯或者不公平，公平不重要，解决问题才重要） 陈述观点（说出事实，表达观点，对比说明） 了解动机（帮助对方调整情绪） 听樊登读书–《关键对话》笔记 好好学习天天向上~分享、交流、共同进步~]]></content>
      <categories>
        <category>读书</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[cccp系统设计-异常重试-分片应用]]></title>
    <url>%2F2018%2F12%2F23%2Fcccp%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%BC%82%E5%B8%B8%E9%87%8D%E8%AF%95-%E5%88%86%E7%89%87%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[任务处理异常重试机制 针对任务处理应用，若出现任务状态为-1（表示异常），或者状态为0（准备状态）且超出一定处理时长的，我们即认为该任务处理出现问题，需要重新尝试处理。 定义一个异常处理模块，针对不同任务设置对应的定时任务——扫描数据库任务表，若扫描到以上状态的任务，则重新发到kafka队列上，等待任务的重试。 通过以上方式保证了任务处理的健壮，然而也衍生了几个问题： 生产集群环境下，多个异常处理的节点，同时扫描到对应的数据信息。 为防止任务信息的重复扫描处理，利用redis添加一个分布式锁，得到锁的应用才进行数据扫描和处理，限制处理的数量，保证应用可及时处理。 某些任务由于延时未及时处理，而异常模块又推送相同任务过来，导致任务处理应用幂等性问题 针对任务处理结果——我们会生成对应的消息数据，通过相关业务字段给消息数据添加了唯一索引，保证相同任务只生成一条消息；这样子避免了消息的重复生成，但都是依靠数据库抛出重复主键的异常来处理，对数据库形成了不小的压力，所以针对任务，当进入处理时，便给该任务在redis缓存里面安置一个处理中的标志，处理完成后删除，重复任务进入时，若在缓存中存在该标志则不再进行处理。 好好学习天天向上-分享、交流、共同进步~]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>异常处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[散谈二-缓存]]></title>
    <url>%2F2018%2F12%2F23%2Fcccp%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[在系统项目的设计开发中，我们避免不了需要到一些数据字典、参数配置、状态常数等，实时的总是从数据库或者文件中读取，是很耗性能的，而且速度也比较慢，所以使用缓存，当然是最佳的选择。 Redis Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. Redis是一个开源的内存数据存储，可被用于做数据库、缓存和消息队列。官方文档中redis是可用做数据库，但实际应用中，redis用的是内存存储，当作数据库并存储到一半容量以上时，其性能是很差的，所以更多的是用作缓存和消息队列。 我们的系统中，使用redis做缓存中间件，应用启动加载时会先将系统相应数据字典、参数配置等加入redis缓存中，当每个应用需要用到时，再从redis中读取，因为储存于内存，响应非常快。在项目中采用两主两从三哨兵的模式，因为项目量级提升，从单节点转变成多节点（集群模式），所以原本只是Jedis（JedisPool）来连接redis进行操作，后面改造为SharedJedis，实现redis的分片，根据一致性Hash ID计算后分配到不同的分片上（即不同的节点redis）。 SharedJedis是jedis的jar包中提供的基于客户端分片的实现。SharedJedis分片相关的代码基本都在redis.clients.util.Sharded类中。下面是Sharded类的构造函数 12345678910/**@param shards，redis服务信息对象的list集合（ShardInfo的子类，如JedisShardInfo，存放了redis子节点的ip、端口、weight等信息）。@param hash算法（默认一致性hash），jedis中指定了两种hash实现，一种是一致性hash，一种是基于md5的实现，在redis.clients.util.Hashing中指定的。@param tagPattern，可以指定按照key的某一部分进行hash分片（比如我们可以将以order开头的key分配到redis节点1上，可以将以product开头的key分配到redis节点2上），默认情况下是根据整个key进行hash分片的。*/public Sharded(List&lt;S&gt; shards, Hashing algo, Pattern tagPattern) &#123; this.algo = algo; this.tagPattern = tagPattern; initialize(shards);&#125; 在Sharded构造函数中调用了initialize方法完成分片的一些初始化操作： 1234567891011121314private void initialize(List&lt;S&gt; shards) &#123; nodes = new TreeMap&lt;Long, S&gt;(); for (int i = 0; i != shards.size(); ++i) &#123; final S shardInfo = shards.get(i); if (shardInfo.getName() == null) for (int n = 0; n &lt; 160 * shardInfo.getWeight(); n++) &#123; nodes.put(this.algo.hash(&quot;SHARD-&quot; + i + &quot;-NODE-&quot; + n), shardInfo); &#125; else for (int n = 0; n &lt; 160 * shardInfo.getWeight(); n++) &#123; nodes.put(this.algo.hash(shardInfo.getName() + &quot;*&quot; + n), shardInfo); &#125; resources.put(shardInfo, shardInfo.createResource()); &#125; &#125; 首先根据redis节点集合信息创建虚拟节点（一致性hash上0~2^32之间的点），通过上面的源码可以看出，根据每个redis节点的name计算出对应的hash值（如果没有配置节点名称，就是用默认的名字），并创建了160weight个虚拟节点，weight默认情况下等于1，如果某个节点的配置较高，可以适当的提高虚拟节点的个数，将更多的请求打到这个节点上。SharedJedis并不支持多个key的操作，例如 keys ；因为多个key计算出来的分片可能不一样，读需要多个节点同时计算后做归并交集才能得到结果，写的时候无法判断所有key是否都写成功，一致性得不到保障。 SharedJedis的这个实现，参照了一致性Hash算法(consistent hashing)。可参考：http://blog.csdn.net/cywosp/article/details/23397179 Guava cacheLoaderGuava是一个超棒的工具类库~Guava工程包含了若干被Google的Java项目广泛依赖的核心库，例如：集合 [collections] 、缓存 [caching] 、原生类型支持 [primitives support] 、并发库 [concurrency libraries] 、通用注解 [common annotations] 、字符串处理 [string processing] 、I/O 等等。 LocalCache是一种很好的优化方案，它可以成倍的提高处理效率。Guava cache只是它其中一种方案选择。在我们的系统功能设计中，我们用到的是LoadingCache。若说Redis为一级缓存，CacheLoader则是二级缓存； 1234567891011//数据加载器CacheLoader&lt;K, T&gt; loader = new CacheLoader&lt;K, T&gt; () &#123; public T load(K Key) throws Exception &#123; // TODO load data. &#125;&#125;;//Guava cache 的创建return CacheBuilder.newBuilder() .maximumSize(1000)//最大容量 .expireAfterWrite(2, TimeUnit.MINUTES)//缓存写入后的过期时间2min .build(loader); 我是用的CacheLoader的方式，先定义一个CacheLoader加载器,然后用CacheBuilder进行构建，流式定义缓存大小、缓存失效时间、缓存刷新时间等等（Guava Cache提供了多种缓存机制）。LoadingCache执行时，先从已有缓存中通过key查找，若没有则执行load方法加载一遍key的值。注意：当执行load查询加载数据也都查询不到时，Loading Cache的get方法会直接抛出空指针异常，这是需要防范的。建议可以配合Option一起使用，即CacheLoader&lt;K,Option&gt;这样子定义。Guava对NPE有其严谨的规范。 LoadingCache有另一种实现方式——Callable 1234567891011121314151617181920public void testcallableCache()throws Exception&#123; Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder().maximumSize(1000).build(); String resultVal = cache.get("Hello", new Callable&lt;String&gt;() &#123; public String call() &#123; //TODO 获取值 System.out.println("Hello "); return value; &#125; &#125;); System.out.println("Hello " + resultVal); resultVal = cache.get("test", new Callable&lt;String&gt;() &#123; public String call() &#123; //TODO 获取值 System.out.println("Test"); return value; &#125; &#125;); System.out.println("test value : " + resultVal); &#125; 好好学习天天向上-分享、交流、共同进步~]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>redis|</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[散谈一-多数据源]]></title>
    <url>%2F2018%2F12%2F23%2Fcccp%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%2F</url>
    <content type="text"><![CDATA[由于项目开发中涉及多个数据库，每个服务又需要连接多个数据库，所以这就需要多数据源切换了。 AbstractRoutingDataSource实现多数据源切换 在spring下我们要进行数据操作： sessionFactory会话工厂、transactionManager事务管理器设置dataSource，数据库连接信息； 获取数据库的连接会话session,通过sessionFactory获取； 通过会话session连接，与事务管理器，实现数据库操作，并保证事务完整。 由此可见，要实现数据源切换，主要是能实现dataSource的动态更改;123Abstract &#123;@link javax.sql.DataSource&#125; implementation that routes &#123;@link #getConnection()&#125;calls to one of various target DataSources based on a lookup key. The latter is usually(but not necessarily) determined through some thread-bound transaction context. AbstractRoutingDataSource–直译为抽象路由数据源，以上是spring中对它的解释：当获取某个数据库连接时，是基于lookup key来确定的。 多数据源的动态切换，在程序运行时，把数据源数据源动态植入到程序中，灵活的进行数据源切换。 基于多数据源的动态切换，我们可以实现读写分离，这么做缺点也很明显，无法动态的增加数据源。 123456//1）动态DataSource ,继承AbstractRoutingDataSourceclass DynamicDataSource extends AbstractRoutingDataSource &#123; protected Object determineCurrentLookupKey() &#123; return DynamicDataSourceContextHolder.getDataSourceType(); &#125;&#125; 在springboot中用代码来配置动态的数据源，实现ImportBeanDefinitionRegistrar接口，应用加载时注册导入bean的定义，实现EnvironmentAware接口是为了获取系统环境信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091/*** @Description 动态注册数据源加入spring容器中管理* 初始化数据源和提供了执行动态切换数据源的工具类* */@Slf4jpublic class DynamicDataSourceRegister implements ImportBeanDefinitionRegistrar, EnvironmentAware&#123; //指定默认数据源(springboot2.0默认数据源是hikari如何想使用其他数据源可以自己配置) private static final String DATASOURCE_TYPE_DEFAULT = "com.zaxxer.hikari.HikariDataSource"; //默认数据源 private DataSource defaultDataSource; //用户自定义数据源 private Map&lt;String, DataSource&gt; customDataSources = new HashMap&lt;&gt;(); @Override public void setEnvironment(Environment environment) &#123; initDefaultDataSource(environment); initCustomDataSources(environment); &#125; private void initDefaultDataSource(Environment env) &#123; // 读取主数据源 Map&lt;String, Object&gt; dsMap = new HashMap&lt;&gt;(); dsMap.put("driver", env.getProperty("spring.datasource.hikari.driver-class-name")); dsMap.put("url", env.getProperty("spring.datasource.hikari.jdbc-url")); dsMap.put("username", env.getProperty("spring.datasource.hikari.username")); dsMap.put("password", env.getProperty("spring.datasource.hikari.password")); defaultDataSource = buildDataSource(dsMap); &#125; private void initCustomDataSources(Environment env) &#123; // 读取配置文件获取更多数据源 String dsPrefixs = env.getProperty("spring.datasource.names"); for (String dsPrefix : dsPrefixs.split(",")) &#123; // 多个数据源 Map&lt;String, Object&gt; dsMap = new HashMap&lt;&gt;(); String firstStr = "spring.datasource."; dsMap.put("driver", env.getProperty(firstStr + dsPrefix + ".hikari.driver-class-name")); dsMap.put("url", env.getProperty(firstStr + dsPrefix + ".hikari.jdbc-url")); dsMap.put("username", env.getProperty(firstStr + dsPrefix + ".hikari.username")); dsMap.put("password", env.getProperty(firstStr + dsPrefix + ".hikari.password")); DataSource ds = buildDataSource(dsMap); customDataSources.put(dsPrefix, ds); &#125; &#125; public DataSource buildDataSource(Map&lt;String, Object&gt; dataSourceMap) &#123; try &#123; Object type = dataSourceMap.get("type"); if (type == null) &#123; type = DATASOURCE_TYPE_DEFAULT;// 默认DataSource &#125; Class&lt;? extends DataSource&gt; dataSourceType; dataSourceType = (Class&lt;? extends DataSource&gt;) Class.forName((String) type); String driverClassName = dataSourceMap.get("driver").toString(); String url = dataSourceMap.get("url").toString(); String username = dataSourceMap.get("username").toString(); String password = dataSourceMap.get("password").toString(); // 自定义DataSource配置 DataSourceBuilder factory = DataSourceBuilder.create().driverClassName(driverClassName).url(url) .username(username).password(password).type(dataSourceType); return factory.build(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; return null; &#125; @Override public void registerBeanDefinitions(AnnotationMetadata annotationMetadata, BeanDefinitionRegistry beanDefinitionRegistry) &#123; Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;Object, Object&gt;(); //添加默认数据源 targetDataSources.put("main", this.defaultDataSource); DynamicDataSourceContextHolder.dataSourceIds.add("main"); //添加其他数据源 targetDataSources.putAll(customDataSources); for (String key : customDataSources.keySet()) &#123; DynamicDataSourceContextHolder.dataSourceIds.add(key); &#125; //创建DynamicDataSource GenericBeanDefinition beanDefinition = new GenericBeanDefinition(); beanDefinition.setBeanClass(DynamicDataSource.class); beanDefinition.setSynthetic(true); MutablePropertyValues mpv = beanDefinition.getPropertyValues(); mpv.addPropertyValue("defaultTargetDataSource", defaultDataSource); mpv.addPropertyValue("targetDataSources", targetDataSources); //注册 - BeanDefinitionRegistry beanDefinitionRegistry.registerBeanDefinition("dataSource", beanDefinition); log.info("Dynamic DataSource Registry"); &#125; 当代理类-动态数据源DynamicDataSource定义好，具体各个dataSource也动态注入spring中，现在需要实现如何更改DynamicDataSource的looku key的变化，用ThreadLocal来保证线程安全,存储对应dataSource的关键字。 123456789101112131415161718192021222324252627public class DynamicDataSourceContextHolder &#123; //存放当前线程使用的数据源类型信息 private static final ThreadLocal&lt;String&gt; contextHolder = new ThreadLocal&lt;String&gt;(); //存放数据源id public static List&lt;String&gt; dataSourceIds = new ArrayList&lt;String&gt;(); //设置数据源 public static void setDataSourceType(String dataSourceType) &#123; contextHolder.set(dataSourceType); &#125; //获取数据源 public static String getDataSourceType() &#123; return contextHolder.get(); &#125; //清除数据源 public static void clearDataSourceType() &#123; contextHolder.remove(); &#125; //判断当前数据源是否存在 public static boolean isContainsDataSource(String dataSourceId) &#123; return dataSourceIds.contains(dataSourceId); &#125;&#125; 多个SessionFactory实现数据源切换 在高并发，一个方法中需要切换多个数据进行操作，还要保证事务管理的情况下，第一种方法中，我们需要频繁的修改threadLocal中的值，及时调整ThreadLocal中的值，否则当线程依旧绑定着上一个key时，容易发生Table not exist的异常，代码逻辑也就变得相对复杂。 在spring4版本中也是支持多数据库切换的，设置多个SessionFactory和transactionManager，对应多个dataSource；主要也是以空间换取的功能实现；通过事务注解即可切换对应的数据源，并保证事务的一致性。 代码就不贴了，DataSource、SessionFactory和transactionManager分别定义多个，一一对应。 好好学习天天向上-分享、交流、共同进步~]]></content>
      <categories>
        <category>系统设计|数据库</category>
      </categories>
      <tags>
        <tag>多数据源|mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java序列化]]></title>
    <url>%2F2018%2F12%2F21%2F%E5%BA%8F%E5%88%97%E5%8C%961%2F</url>
    <content type="text"><![CDATA[Java原生流的方法进行的序列化类实现Serializable接口，标记该类对象可以被序列化。此时，Java序列化写入不仅是完整的类名，也包含整个类的定义，包含所有被引用的类，影响性能和效率；通过实现Externalizable接口，这是可能优化Java序列化的。实现此接口，避免写出整个类定义，只是类名被写入。它需要你实施readExternal和writeExternal方法方法的，所以需要做一些工作，但相比仅仅是实现Serializable更快，更高效。123456789//对象转成字节码 ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();ObjectOutputStream outputStream = new ObjectOutputStream(byteArrayOutputStream);outputStream.writeObject(GetUser());byte[] bytes = byteArrayOutputStream.toByteArray();outputStream.close(); //字节码转换成对象 ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes); ObjectInputStream inputStream = new ObjectInputStream(byteArrayInputStream); User result = (User) inputStream.readObject(); inputStream.close(); Json序列化FastJson序列化Protobuff序列化 好好学习天天向上-分享、交流、共同进步~]]></content>
      <categories>
        <category>序列化</category>
      </categories>
      <tags>
        <tag>Java|序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书-解忧杂货店]]></title>
    <url>%2F2018%2F12%2F10%2F%E8%A7%A3%E5%BF%A7%E6%9D%82%E8%B4%A7%E5%BA%97%2F</url>
    <content type="text"><![CDATA[看过不少日本动漫，但很少读过日本作者的书籍，看了一半《解忧杂货店》，我已经被东野圭吾的文字抓进去了。 19世纪七八十年代与现代，相差34年的时空交错； 杂货店老板–一位年迈的老人浪矢雄治，为周边的小孩大人提供答疑解忧，从不敷衍了事。卷铁门旁的邮箱–收取来咨询的信封，后门牛奶箱则放置回信。老人周而复始的思考每位来咨询的问题，绞尽脑汁地写下回信。 交错的时空，神奇的梦境，让老人得以知道他的回复，影响了哪些人，产生了哪些意义；或许言者无意，然听者有心；老人心里始终谦逊，认真的对待每个问题。他知道，每个烦恼忧愁的咨询后面，当事者都有了确定的选择，然而他们还是需要有一个可以商量的对象，这是心里精神上的需求。。 最后的咨询，一张空白的信纸，这是老爷子遇到的最难的一次咨询，也是最后的一次~之前所有咨询的信，都描述了各个咨询者的问题、烦恼，或者这就是一张地图，有线有方向也有点，只是咨询的主人公不知道怎么走，抑或是不知道往哪走；而这空白的信纸，主人公可能迷茫着不知道该咨询什么，不知道自己有什么方向可寻，在老人看来，或许这白纸，更展现着更大的可能性，更大的自由，为自己的生活去努力，那就好。 当所有咨询与烦恼的情节串联了起来，故事的玄妙精彩不言而喻。生活也好，工作也罢，梦想理想，我们都应该尽自己最大努力的实现，去践行~存在即是合理，不必太过执着忧愁，珍惜当下，珍惜眼前人，我们都需要有更大的胸怀去分享/去交流！ 好好学习天天向上-分享、交流、共同进步~]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>东野圭吾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式学习一]]></title>
    <url>%2F2018%2F11%2F20%2F%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[踉踉跄跄coding几年，懂得coding，知道OOD，才明白更应该去理解面向对象设计的原则。 设计模式，是前辈大神们经过实践而总结出来的经验。以设计原则去设计编程，为的就是让代码更易于理解，保证代码的可靠性，确保系统项目的扩展性。~代码不是一个人的，让多数人都能去读懂和理解，才是好代码 设计原则有这么一段概括: 单一职责原则告诉我们实现类、接口要职责单一； 里氏替换原则告诉我们不要破坏继承体系； 依赖倒置原则告诉我们要面向接口编程； 接口隔离原则告诉我们在设计接口的时候要精简单一； 迪米特法则告诉我们要降低耦合； 而开闭原则是总纲，它告诉我们要对扩展开放，对修改关闭。 单一职责原则 Single Responsibility Principle, 简称SRP 单一职责原则的定义是:应该有且仅有一个原因引起类的变更；从业务角度来说，引起一个接口or类发生变化的原因，应该是一个有限制的单纯的最小业务单元； 例子1：RBAC模型，Role-Based Access Control,基于角色的的访问控制。系统用户信息定义是我们总遇到的业务之一。用户信息接口，若我们直接定义用户属性（姓名、密码、所在部门）+ 用户行为（修改姓名、修改密码等）在一个接口中，该接口同时承担用户属性信息和用户行为的职责，这是容易引起混淆的，这不符合单一职责原则的。拆分为两个接口，不同场景下使用不同的接口（信息的查询和操作分开），各司其职，一目了然。 例子2：电话通话的用例定义：拨号、通话、回应、挂机。一个接口IMobile将电话通话全涵盖。看似可以，但包含两层职责：a.拨号和挂断，这是通话协议管理; b.通话回应则是数据传送。实际业务，这两层职责相关联，若两个接口两个类，一个电话要两个类来组合定义，强耦合关系，增加了类的复杂度，这似乎也不太合理。换种角度，两种职责，定义两个接口，由一个电话类实现这两个接口，将两个职责融合在一个类中。对外发布仅仅是接口，而非实现类，这样也体现了接口的单一职责。 通过上面的例子，我们来总结一下单一职责原则有什么好处： 类的复杂性降低，实现什么职责都有清晰明确的定义； 可读性提高，复杂性降低，那当然可读性提高了； 可维护性提高，可读性提高，那当然更容易维护了； 变更引起的风险降低，变更是必不可少的，如果接口的单一职责做得好，一个接口修改只对相应的实现类有影响，对其他的接口无影响，这对系统的扩展性、维护性都有非常大的帮助。 单一职责原则提出了一个编写程序的标准，用“职责”或“变化原因”来衡量接口或 类设计得是否优良，但是“职责”和“变化原因”都是不可度量的，因项目而异，因环境而异。具体业务需求具体分析，灵活转变。 里氏替换原则 Liskov Substitution Principle，LSP 第一种定义，也是最正宗的定义：If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T,the behavior of P is unchanged when o1 is substituted for o2 then S is a subtype of T.（如果对每一个类型为S的对象o1，都有类型为T的对 象o2，使得以T定义的所有程序P在所有的对象o1都代换成o2时，程序P的行为没有发生变化，那么类型S是类型T的子类型。） 第二种定义：Functions that use pointers or references to base classes must be able to use objects of derived classes without knowing it.（所有引用基类的地方必须能透明地使用其子类的对象。） 依赖倒置原则接口隔离原则迪米特法则开闭原则 好好学习天天向上-分享、交流、共同进步~]]></content>
      <categories>
        <category>Design pattern</category>
      </categories>
      <tags>
        <tag>设计原则|面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[策略模式--实现规则配置以处理任务]]></title>
    <url>%2F2018%2F11%2F05%2F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F-%E5%AE%9E%E7%8E%B0%E8%A7%84%E5%88%99%E9%85%8D%E7%BD%AE%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[Welcome to my T-SPACE~ 由于业务需求，会有不同渠道的信息组合，现有系统设计耦合度太高，不好扩展。所以对此进行重构，添加规则配置，以应对不同组合的需求信息获取和执行。这里边用到了策略模式。 原理策略模式的概念引用阎宏博士的《JAVA与模式》一书描述：策略模式属于对象的行为模式。其用意是针对一组算法，将每一个算法封装到具有共同接口的独立的类中，从而使得它们可以相互替换。策略模式使得算法可以在不影响到客户端的情况下发生变化。 实现原理面向对象编程有三大特性：封装、继承、多态。 封装–隐藏了类的内部实现机制，对外只暴露相关的访问方法，内部实现细节对外是不可知的。 继承–对父类代码的重用。 多态–在程序中定义的引用变量所指向的具体类型，以及通过该变量而指向的方法调用有不同种类型/实现（多种形态），具体引用了什么方法要在程序运行时依据具体指向的实例对象来决定。因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。 该策略模式的实现也是利用了多态的这一特性。 代码实现接口类123456789public interface ProcessStrategy&lt;T&gt; &#123; /** * @param result 结果集 * @param params 参数集 * @param key 结果集映射key * */ void operate(Map result, List&lt;T&gt; params, String key);&#125;` 接口实现1234567891011121314151617public class AtestProcess implements ProcessStrategy&lt;String&gt; &#123; @Override public void operate(Map result, List&lt;String&gt; params, String key) &#123; System.out.println(params.get(0)); //TODO 算法逻辑 result.put(key,"A"); &#125;&#125;public class AtestProcess implements ProcessStrategy&lt;Integer&gt; &#123; @Override public void operate(Map result, List&lt;Integer&gt; params, String key) &#123; System.out.println(params.get(0)); //TODO 算法逻辑 result.put(key,"B"); &#125;&#125; 定义工厂类定义Factory，程序运行中通过该类获取具体实例对象：12345678910111213public class ProcessFactory &#123; private static ProcessStrategy instance = null; public static ProcessStrategy getInstance(String clzName)&#123; try &#123; instance = (ProcessStrategy)Class.forName(clzName).newInstance(); &#125;catch (Exception e)&#123; System.out.println("Class not found.check the param 'clzName'. "); return null; &#125; return instance; &#125;&#125; 枚举配置通过以上代码，策略模式相关的实现大致完成，具体业务代码中使用ProcessFactory即可获取不同策略的实现方法，而要实现配置化，自动装载配置以应对不同的场景逻辑，还需要实现定义好我们的配置枚举类（配置表） 12345678910111213141516171819202122public enum TypeEnum &#123; TYPE_ENUM_A("A","com..impl.AtestProcess"), TYPE_ENUM_B("B","com..impl.BtestProcess"); private String key ; private String value; TypeEnum(String key, String value) &#123; this.key = key; this.value = value; &#125; public static String getValue(String key) &#123; for (TypeEnum typeEnum : TypeEnum.values())&#123; if (typeEnum.key.equalsIgnoreCase(key))&#123; return typeEnum.value; &#125; &#125; return null; &#125;&#125; 12345678910public String HelloTest()&#123; Map&lt;String,Object&gt; result = new HashMap&lt;&gt;(); List params = Arrays.asList("1","3","12"); String className = TypeEnum.getValue("A"); ProcessStrategy ps = ProcessFactory.getInstance(className); ps.operate(result, params, "testA"); String className = TypeEnum.getValue("B"); ps = ProcessFactory.getInstance(className); ps.operate(result, params, "testB"); &#125; 业务场景中需要走A还是走B，将条件记录于数据库/缓存redis/property文件中，当程序运行时再和TypeEnum中匹配，通过ProcessFactory捕获相应的实例对象来处理。当业务扩展，策略增多，我们只需要添加具体的接口实现，另外配置枚举对应，而不影响原来代码的主业务执行。 策略模式一方面也帮我们减少了if/else代码块过多而带来的sonar问题。 好好学习天天向上-分享、交流、共同进步~]]></content>
      <categories>
        <category>Design pattern</category>
      </categories>
      <tags>
        <tag>Java|模式|多态</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从0开始的小程序之旅]]></title>
    <url>%2F2018%2F10%2F18%2F%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%B0%8F%E7%A8%8B%E5%BA%8F%E4%B9%8B%E6%97%85%2F</url>
    <content type="text"><![CDATA[Welcome to T-SPACE~本文将介绍小程序的小白入手，从小程序的申请到小程序的开发，一起入门！ 开发工具 开发者工具 微信的开发者工具需要微信扫描登陆后才能打开。 新建项目选择小程序项目，选择代码存放的硬盘路径，填入刚刚申请到的小程序的 AppID，给你的项目起个名字，最后，勾选 “创建 QuickStart 项目” （注意: 你要选择一个空的目录才会有这个选项），点击确定，你就得到了你的第一个小程序了。 点击工具上的编译按钮，可以在工具的左侧模拟器界面看到这个小程序的表现，也可以点击预览按钮，通过微信的扫一扫在手机上体验你的第一个小程序。 小程序结构 1234567- pages --&gt; 小程序所有页面存放的文件夹- libs --&gt; 引进的js库- img --&gt; 图片文件夹1. app.json // 后缀的 JSON 配置文件2. app.wxml // 后缀的 WXML 模板文件3. app.wxss // 后缀的 WXSS 样式文件4. app.js // 后缀的 JS 脚本逻辑文件 小程序配置 app.jsonapp.json 是当前小程序的全局配置，包括了小程序的所有页面路径、界面表现、网络超时时间、底部 tab 等。QuickStart 项目里边的 app.json 配置内容如下：123456789101112&amp;#123; &quot;pages&quot;:[ &quot;pages/index/index&quot;, &quot;pages/logs/logs&quot; ], &quot;window&quot;:&amp;#123; &quot;backgroundTextStyle&quot;:&quot;light&quot;, &quot;navigationBarBackgroundColor&quot;: &quot;#fff&quot;, &quot;navigationBarTitleText&quot;: &quot;WeChat&quot;, &quot;navigationBarTextStyle&quot;:&quot;black&quot; &amp;#125;&amp;#125; 我们简单说一下这个配置各个项的含义: pages字段 —— 用于描述当前小程序所有页面路径，这是为了让微信客户端知道当前你的小程序页面定义在哪个目录。 window字段 —— 定义小程序所有页面的顶部背景颜色，文字颜色定义等。其他配置项细节可以参考小程序的配置 app.json。 工具配置 project.config.json通常大家在使用一个工具的时候，都会针对各自喜好做一些个性化配置，例如界面颜色、编译配置等等，当你换了另外一台电脑重新安装工具的时候，你还要重新配置。考虑到这点，小程序开发者工具在每个项目的根目录都会生成一个 project.config.json，你在工具上做的任何配置都会写入到这个文件，当你重新安装工具或者换电脑工作时，你只要载入同一个项目的代码包，开发者工具就自动会帮你恢复到当时你开发项目时的个性化配置，其中会包括编辑器的颜色、代码上传时自动压缩等等一系列选项。 页面配置 page.json与上面的app.json类似，但是是针对具体某一个页面的，让开发者可以独立定义每个页面的一些属性。 WXML 模板 编写网页时我们经常都是采用HTML+CSS+JS的组合，而WXML就相当于html，用来描述当前这个页面的结构。 在网页的一般开发流程中，我们通常会通过 JS 操作 DOM (对应 HTML 的描述产生的树)，以引起界面的一些变化响应用户的行为。例如，用户点击某个按钮的时候，JS 会记录一些状态到 JS 变量里边，同时通过 DOM API 操控 DOM 的属性或者行为，进而引起界面一些变化。当项目越来越大的时候，你的代码会充斥着非常多的界面交互逻辑和程序的各种状态变量，显然这不是一个很好的开发模式，因此就有了 MVVM 的开发模式（例如 React, Vue），提倡把渲染和逻辑分离。简单来说就是不要再让 JS 直接操控 DOM，JS 只需要管理状态即可，然后再通过一种模板语法来描述状态和界面结构的关系即可。小程序的框架也是用到了这个思路，如果你需要把一个 Hello World 的字符串显示在界面上。WXML 是这么写 :1&lt;text&gt;&amp;#123;&amp;#123;msg&amp;#125;&amp;#125;&lt;/text&gt; JS 只需要管理状态即可:1this.setData(&amp;#123; msg: &quot;Hello World&quot; &amp;#125;) 通过 &#123;&#123; &#125;&#125; 的语法把一个变量绑定到界面上，我们称为数据绑定。仅仅通过数据绑定还不够完整的描述状态和界面的关系，还需要 if/else, for等控制能力，在小程序里边，这些控制能力都用 wx: 开头的属性来表达。 WXSS 样式WXSS 具有 CSS 大部分的特性，小程序在 WXSS 也做了一些扩充和修改。新增了尺寸单位。在写 CSS 样式时，开发者需要考虑到手机设备的屏幕会有不同的宽度和设备像素比，采用一些技巧来换算一些像素单位。WXSS 在底层支持新的尺寸单位 rpx ，开发者可以免去换算的烦恼，只要交给小程序底层来换算即可，由于换算采用的浮点数运算，所以运算结果会和预期结果有一点点偏差。提供了全局的样式和局部样式。和前边 app.json, page.json 的概念相同，你可以写一个 app.wxss 作为全局样式，会作用于当前小程序的所有页面，局部页面样式 page.wxss 仅对当前页面生效。此外 WXSS 仅支持部分 CSS 选择器 JS 交互逻辑一个服务仅仅只有界面展示是不够的，还需要和用户做交互：响应用户的点击、获取用户的位置等等。在小程序里边，我们就通过编写 JS 脚本文件来处理用户的操作。12&lt;view&gt;&amp;#123;&amp;#123; msg &amp;#125;&amp;#125;&lt;/view&gt;&lt;button bindtap=&quot;clickMe&quot;&gt;点击我&lt;/button&gt; 点击 button 按钮的时候，我们希望把界面上 msg 显示成 “Hello World”，于是我们在 button 上声明一个属性: bindtap ，在 JS 文件里边声明了 clickMe 方法来响应这次点击操作：12345Page(&amp;#123; clickMe: function() &amp;#123; this.setData(&amp;#123; msg: &quot;Hello World&quot; &amp;#125;) &amp;#125;&amp;#125;) 预览使用开发者工具可以预览小程序，帮助开发者检查小程序在移动客户端上的真实表现。点击开发者工具顶部操作栏的预览按钮，开发者工具会自动打包当前项目，并上传小程序代码至微信的服务器，成功之后会在界面上显示一个二维码。使用当前小程序开发者的微信扫码即可看到小程序在手机客户端上的真实表现。 上传代码同预览不同，上传代码是用于提交体验或者审核使用的。点击开发者工具顶部操作栏的上传按钮，填写版本号以及项目备注，需要注意的是，这里版本号以及项目备注是为了方便管理员检查版本使用的，开发者可以根据自己的实际要求来填写这两个字段。上传成功之后，登录小程序管理后台 - 开发管理 - 开发版本 就可以找到刚提交上传的版本了。可以将这个版本设置 体验版 或者是 提交审核 小程序的版本 版本 说明 开发版本 使用开发者工具，可将代码上传到开发版本中。开发版本只保留每人最新的一份上传的代码。点击提交审核，可将代码提交审核。开发版本可删除，不影响线上版本和审核中版本的代码。 审核中版本 只能有一份代码处于审核中。有审核结果后可以发布到线上，也可直接重新提交审核，覆盖原审核版本。 线上版本 线上所有用户使用的代码版本，该版本代码在新版本代码发布后被覆盖更新。 好好学习天天向上-分享、交流、共同进步~]]></content>
      <categories>
        <category>微信小程序</category>
      </categories>
      <tags>
        <tag>practise|小程序|小白</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人博客搭建]]></title>
    <url>%2F2018%2F08%2F05%2F%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[T-Space我的个人博客网站搭建。 搭建个人博客网站若要自己购买服务器来构建，着实比较麻烦，也不知道能不能稳定的运行。而Github提供了一个Github Pages的服务，真的让人眼前一亮。GitHub Pages is designed to host your personal, organization, or project pages from a GitHub repository. Github项目搭建将我们的博客项目挂载到Github上去，借由GitHub将我们的项目静态页面发布，便可实现了我们的博客网站。 注册自己的GitHub账号 登录github上，创建一个仓库repository，存放我们的项目文件; 填写仓库的属性(仓库名和描述)，注意：这个仓库名比较特殊，取名格式必须为username.github.io，用户名为github的用户名,创建后的网站访问地址即为此username.github.io。 setting设置，在创建好仓库后，点击仓库中的setting，找到GitHub Pages，选择你要构建发布的分支。OK~ Hexo搭建Github上也有网站主题的一个选择（Jekyll），不过我选用的是Hexo——一个可以帮我们通过md文件生成html静态页面（可设置不同主题模板），并且支持上传到我们对应的服务器的强大工具。 Hexo安装 安装gitbash和nodejs；安装过程略… 通过在gitbash上用npm工具进行安装hexo：npm i -g hexo 进行Hexo的初始化工作：hexo init 初始化后即会生成如下文件结构: 文件/文件夹 说明 node_modules 依赖包 public 存放的是生成的页面，这个目录最终会发布到服务器 scaffolds 命令生成文章等的模板，一些通用的markdown模板 source 用命令创建的各种文章 source/_posts 发布的文章 source/_drafts 草稿文件 themes 博客的模板 _config.yml 配置文件 themes/landscape/_config.yml landscape主题的配置文件 db.json source解析所得到的 package.json 项目所需模块项目的配置信息 Hexo 配置_config.yml分两种：1）网站的配置文件；2）主题的配置文件 在hexo目录下的_config.yml——网站配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Site 信息title: T-SPACEsubtitle:description: tigutf的个人博客author: Tigutflanguage: zh-Hanstimezone:# URL 网址设置## 如果网站是放在子目录中，将url设置成&apos;http://yoursite.com/child&apos;，将root设置成&apos;/child/&apos;url: http://tigutf.github.ioroot: /# 文章链接地址格式 。即文章存放的目录。permalink: :year/:month/:day/:title/permalink_defaults:# Directory## 资源文件——博客文件，会被上传到github上source_dir: source## 静态文件生成后存放在公共文件夹下public_dir: public## 标签tag_dir: tags## 档案archive_dir: archives## 分类category_dir: categories## 代码文件夹code_dir: downloads/code## 国际化文件夹i18n_dir: :langskip_render:# Writing## 新建文章的默认名称new_post_name: :title.md # File name of new posts## 默认布局模板是post，而不是draft和pagedefault_layout: post## 是否将标题转换成标题形式（首字母大写）titlecase: false # Transform title into titlecase## 在新标签页面中打开网页external_link: true # Open external links in new tabfilename_case: 0## 是否渲染草稿render_drafts: falsepost_asset_folder: false## 把链接改为与根目录的相对位址relative_link: false## 显示未来的文章future: true## 高亮设置highlight: enable: true line_number: true auto_detect: false ### 自动检测语言 tab_replace:# Home page setting 主页页面设置# path: Root path for your blogs index page. (default = &apos;&apos;) 你的博客索引页根目录# per_page: Posts displayed per page. (0 = disable pagination) 每页显示的文章量# order_by: Posts order. (Order by date descending by default) 文章排序依据，默认按日期排序index_generator: path: &apos;&apos; per_page: 10 order_by: -date# Category &amp; Tag 分类与标签default_category: uncategorized## 分类别名category_map:## 标签别名tag_map:# Date / Time format 日期格式## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination 分页## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions 拓展插件配置## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/## 主题配置，使用的主题是nexttheme: next# Deployment 部署配置## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:tigutf/tigutf.github.io.git branch: master ## 用master分支打包部署 以上就是我Hexo的网站配置，详细请看注释。 hexo官方主题提供了许多主题来丰富我们的博客，可根据自己喜好选择不同的主题。这边网站主题我自己选用的是NexT。找到主题所在的github地址url，git clone url 到 hexo/themes 目录下即可。 NexT主题下也还有多种模式页面供你选择，有_config.yml配置文件可进行调整，具体请参考Next主题官网主题配置. 懒得更换主题的话也可以使用默认：landscape。 Hexo 命令hexo init [folder] 初始化一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站. hexo new [layout] [title] 新建一篇文章(.md文件)。如果没有设置layout的话，默认使用 config.yml中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 hexo version 查看版本 hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public) hexo g ==&gt; hexo generate 生成静态文件 hexo s ==&gt; hexo server 本地预览 hexo d ==&gt; hexo deploy 部署，可与hexo g合并为 hexo d -g 好好学习天天向上-分享、交流、共同进步~]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>github|hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello Hexo]]></title>
    <url>%2F2018%2F01%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 好好学习天天向上-分享、交流、共同进步~]]></content>
  </entry>
  <entry>
    <title><![CDATA[读读HashMap(2)]]></title>
    <url>%2F2018%2F01%2F05%2F%E8%AF%BB%E8%AF%BBHashMap2%2F</url>
    <content type="text"><![CDATA[网上有很多对HashMap，HashTable几个集合类的对比与解说,看了下源码，记下笔记~ HashMap操作Java1.6 HashMap—PUT put操作，基于Java 1.6的源码如下: 12345678910111213141516171819202122232425//1.6public V put(K key, V value) &#123; //如果table数组为空数组&#123;&#125;，进行数组填充（为table分配实际内存空间），入参为threshold，此时threshold为initialCapacity 默认是1&lt;&lt;4(24=16) if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; //如果key为null，存储位置为table[0]或table[0]的冲突链上 if (key == null) return putForNullKey(value); int hash = hash(key);//对key的hashcode进一步计算，确保散列均匀 int i = indexFor(hash, table.length);//获取在table中的实际位置 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; //如果该对应数据已存在，执行覆盖操作。用新value替换旧value，并返回旧value Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++;//保证并发访问时，若HashMap内部结构发生变化，快速响应失败 addEntry(hash, key, value, i);//新增一个entry return null;&#125; 1234567891011/* 这个方法的主要作用是防止质量较差的哈希函数带来过多的冲突（碰撞）问题。 Java中int值占4个字节，即32位。根据这32位值进行移位、异或运算得到一个值。*/static int hash(int h) &#123; // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 1234567/* indexFor返回hash值和table数组长度减1的与运算结果。 使用length-1是为了保证结果的最大值是length-1，不会产生数组越界问题。*/static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 当执行addEntry，若增加元素后table的大小大于threshold（容器大小与负载因子的乘机），则需要对当前数组进行重置大小（拓展为原来长度的两倍），调用resize(int capacity) 123456789101112131415161718192021222324252627282930313233343536373839404142void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; // 当容量已经到达允许的最大值，即MAXIMUN_CAPACITY，则不再拓展容量； // 而将装载拓展的界限值设为计算机允许的最大值。 if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; // 创建新数组，容量为指定的容量 Entry[] newTable = new Entry[newCapacity]; transfer(newTable); table = newTable; // 设置下一次需要调整数组大小的界限 threshold = (int)(newCapacity * loadFactor);&#125;void transfer(Entry[] newTable) &#123; // 保留原数组的引用到src中， Entry[] src = table; // 新容量使新数组的长度 int newCapacity = newTable.length; // 遍历原数组 for (int j = 0; j &lt; src.length; j++) &#123; // 获取元素e Entry&lt;K,V&gt; e = src[j]; if (e != null) &#123; // 将原数组中的元素置为null src[j] = null; // 遍历原数组中j位置指向的链表 do &#123; Entry&lt;K,V&gt; next = e.next; // 根据新的容量计算e在新数组中的位置 int i = indexFor(e.hash, newCapacity); // 将e插入到newTable[i]指向的链表的头部 e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null); &#125; &#125;&#125; Java1.8 HashMap—PUT 1.8之前，HashMap主干是数组与链表的结合，而1.8版本中发生了一些改变，转变成了基于数组+链表+红黑树实现： 1.8版本 基础数组类型变成Node[]，如下： 12345678910111213141516 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; &#125; static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red;&#125; transient Node&lt;K,V&gt;[] table; put操作，基于Java 1.8的源码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //当前HashMap为空时，初始化数组大小 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //table数组的位置的算法是:i = (n - 1) &amp; hash，将数组长度减1后与运算hash //当计算得到的hash值为空，则新增一个节点 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; //当hash计算得到的值相同（哈希碰撞） Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //当节点为红黑树时，将结果插入到红黑树中 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //首个链表节点为链表 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; HashMap将插入的键值对封装在Node对象中，每个Node对象含有hash值，键对象key，值对象value。当哈希值冲突后，新增的Node会被next变量指向，组成链表。当该链表的长度超过8，将其转换为红黑树节点。 这里有一个注意的地方，table数组的位置的计算算法是: i = (n - 1) &amp; hash; n是数组的长度，hash是key的哈希值（int型32位）高16位的返回值；HashMap的数组长度是由限制的，一定是2的幂，二进制表示形式（10，100，1000，10000,,,），当减1之后得（01，11，111，1111,,,），(n-1)&amp;hash 等价于 1111…1 &amp; XXXXXXXXXXXXXXXXX ；用hash与(n-1)做位置运算相比%运算更高效，这可能就是HashMap数组长度为2的幂的原因，并且这种巧妙的设计也保证位置i不会超过数组长度。 12345678910111213141516171819202122final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; //初始长度为0 int oldThr = threshold;//如果HashMap构造方指定了初始长度和加载因子，threshold会被计算出来 int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //第二次及以后的扩容走这里 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //初始化长度和加载因子走这里 else &#123; // zero initial threshold signifies using defaults //初始默认执行这个分支 newCap = DEFAULT_INITIAL_CAPACITY; //默认长度 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); //默认临界值 &#125;&#125; 数组的长度和位置计算过后，则需要在该位置的首个链表节点插入元素，由于哈希冲突与链表长度达8以上后会转变成红黑树的规则，所以需要多了解下下面一段代码： 12345678910111213for (int binCount = 0; ; ++binCount) &#123;if ((e = p.next) == null) &#123; //@1如果遍历到链表的末尾，说明遍历的过程中未找到key相等的节点，将键值对插入末尾 p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); //@3在链表末尾插入新节点后，链表的长度达到8，此时方法treeifyBin(tab, hash)将链表转换为红黑树 break;&#125;if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) //@2 如果遍历链表的过程中，存在哈希值一致，引用相等或equals相等的节点，终止遍历，新键值对的值会替换这个节点上原来的值。 break;p = e;&#125; Java1.8 HashMap—GET取出算法123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; 取出算法其实就是插入算法的逆向过程，你可能直接从table[i]中取走键值对，也可能是红黑树或者链表中的一个节点。要注意的是只满足equlas相等并不能有效取出元素，还必须满足哈希值相等，所以要考虑重写key的hashCode()方法。 好好学习天天向上-分享、交流、共同进步~ 部分内容参考：https://www.jianshu.com/p/df4a907ef4ef]]></content>
      <categories>
        <category>集合</category>
        <category>HashMap</category>
      </categories>
      <tags>
        <tag>Java|Map|集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读读HashMap(1)]]></title>
    <url>%2F2017%2F10%2F05%2F%E8%AF%BB%E8%AF%BBHashMap%2F</url>
    <content type="text"><![CDATA[网上有很多对HashMap，HashTable几个集合类的对比与解说,看了下源码，记下笔记~ 文章部分参考如下： http://www.cnblogs.com/skywang12345/p/3310835.html https://www.cnblogs.com/chengxiao/p/6059914.html HashMap基础结构HashMap的基础属性HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。HashMap 继承于AbstractMap，实现了Map、Cloneable、java.io.Serializable接口。12public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; HashMap底层维护的是数组+链表(链地址法),它里面有两个参数：“初始容量” 和 “加载因子”。 12345678910111213141516171819//默认的初始化大小static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16//最大的容量值，hashMap的容量大小必须是2的n次幂（2^30）static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//负载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;/** * An empty table instance to share when the table is not inflated. */static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;;/** * The table, resized as necessary. Length MUST Always be a power of two. */transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; DEFAULT_INITIAL_CAPACITY 即初始容量，HashMap创建时的初始容量:1&lt;&lt;4 表示 二进制的01，向左偏移4位得到 10000，转换成十进制即为16 DEFAULT_LOAD_FACTOR 即加载因子，是哈希表在其容量自动增加之前可以达到多满的一种尺度，默认为0.75。当哈希表中的条目数超出了加载因子与当前容量的乘积时，则要对该哈希表进行 rehash 操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数。 HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对。当发生哈希碰撞时（两个值计算得到的哈希值相同），则存储到对应下标的数组格子的链表里。（哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了链地址法，也就是数组+链表的方式，） HashMap的构造函数 HashMap有4种构造函数 123456789101112131415161718192021222324252627282930//以默认的初始化大小16和负载因子0.75，构造对象/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;//指定初始化大小public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;//指定容量大小和负载因子public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;//指定mappublic HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; 在前三种构造器当中，没有为数组Entry table分配内存空间，而是在执行put操作的时候才真正构建table数组；而第四种，指定了Map，构造器中调用putMapEntries(m, false);则会构建table数组。 HashMap 原理基于Java1.6，在上面的基础信息中我们已经了解HashMap的结构，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的. 如果计算定位到的数组位置不含链表（当前entry的next指向null），那么对于查找、添加操作很快，仅需一次寻址即可，时间复杂度O(1); 如果定位到的位置包含链表，对于添加操作，首先遍历链表，存在则覆盖，否则新增，其时间复杂度O(n);对于查找操作，仍需遍历链表，逐一对比key对象查找； 所以，从性能考虑，HashMap中的链表出现越少，性能才会越好。 好好学习天天向上-分享、交流、共同进步~]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java | Map | 集合</tag>
      </tags>
  </entry>
</search>
